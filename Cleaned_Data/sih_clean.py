# -*- coding: utf-8 -*-
"""SIH_CLEAN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AkfzQKwb1mANaGYlRFLWMLxfSfnrzFGS
"""

import glob
import nltk
nltk.download('stopwords')
import pandas as pd
import io
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import re
stop_words = set(stopwords.words('english')) 

path = 'D:\\SIH\\Vidhu\\Cleaned_Phy\\'
filelist = glob.glob(path + "/*.csv")
for file in filelist:
    df = pd.read_csv(file, error_bad_lines=False)
    
    pf=df.iloc[:,0].tolist()

    dff=[]
    for line in pf:
      dff=dff+str(line).split()


    
    final=pd.DataFrame(data=dff, index=None, columns=['A'])
    final=final[(final.A.astype(str).str.len()>2)]
    final

    final['A'] = final['A'].str.replace(',','')
    final['A'] = final['A'].str.replace("'",'')
    final['A'] = final['A'].str.replace('"','')
    final['A'] = final['A'].str.replace('.','')
    final['A'] = final['A'].str.replace('\d+'," ")
    final['A'] = final['A'].str.replace(';','')
    final['A'] = final['A'].str.replace(':','')
    final['A'] = final['A'].str.replace('+','')
    final['A'] = final['A'].str.replace('-','')
    final['A'] = final['A'].str.replace('?','')
    final['A'] = final['A'].str.replace('%','')
    final['A'] = final['A'].str.replace('^','')


    filteredtext1 = []
    for word in final['A']:
      
      if word.lower() not in stop_words:
        filteredtext1.append(word)
    filteredtext1

    cleanfiltered=[]
    for txt in filteredtext1:
      txt = txt.replace(' ','')
          
      x = re.search("\([a-zA-Z]\)", txt)
      if(x!=None):
        txt=txt[:x.start()]+txt[x.end():]
      if txt.lower() not in stop_words:
        if(len(txt)>1):
          txt = txt.replace('(','')
          txt = txt.replace(')','')
          txt = txt.replace('-','')
          txt = txt.replace('_','')
          
          cleanfiltered.append(txt.lower().strip())
    

    cleanfiltered[:]=list(set(cleanfiltered))

    tr=pd.DataFrame(data=cleanfiltered, index=None, columns=['Words'])

    df = pd.concat([df.reset_index(), tr], axis=1)

    df.to_csv(file.rstrip(".csv")+"_cleaned"+".csv")